# ğŸ¤– Chatbot Project
A Retrieval-Augmented Generation (RAG) chatbot built with LangChain, Streamlit, Python and Hugging Face.

---

## ğŸ“‚ Project Structure

```
chatbot/
â”‚â”€â”€ app.py             # Streamlit UI
â”‚â”€â”€ main.py            # Main script
â”‚â”€â”€ rag_chain.py       # RAG pipeline
â”‚â”€â”€ data_ingestion.py  # Data ingestion scripts
â”‚â”€â”€ docloaderui.py     # Document loader UI
â”‚â”€â”€ tts.py             # Text-to-speech
â”‚â”€â”€ chatbot_db/        # Vector database
â”‚â”€â”€ Panchatantra.pdf   # Example document
â”‚â”€â”€ README.md          # Project instructions
```

---

## ğŸ”‘ Set up environment variables
Create a `.env` file in the root with your API keys:
```
OPENAI_API_KEY=your_api_key_here
```
(or use `GOOGLE_API_KEY=...` if youâ€™re using Google GenAI)

---

## â–¶ï¸ Running the App

### ğŸ”¹ UI Mode (Streamlit)
Run these scripts for the chatbot with UI:
```bash
python docloaderui.py
streamlit run app.py
```

### ğŸ”¹ Normal Python Mode
Run these scripts for the terminal-based chatbot:
```bash
python data_ingestion.py
python main.py
```

---

âœ… **Note:**  
- You do **not** need to run `rag_chain.py` directly.  
- Itâ€™s automatically imported by `main.py` and `app.py`.  
